{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN0aYgpr7ts2JKlGxoEL9X+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cora-hai/ULTRA/blob/main/project_ultra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rSceatPijUg4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bd9784-12c9-46cc-8af4-12dbbbd54708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ULTRA'...\n",
            "remote: Enumerating objects: 129, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 129 (delta 57), reused 54 (delta 53), pack-reused 48 (from 1)\u001b[K\n",
            "Receiving objects: 100% (129/129), 7.61 MiB | 30.11 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ],
      "source": [
        "# clone forked repository\n",
        "!git clone https://github.com/cora-hai/ULTRA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# go to relevant directory\n",
        "%cd ULTRA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy3ElFqUkqEp",
        "outputId": "23d84de2-306c-442f-b591-5e9857843089"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ULTRA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8rbhdzZlMsa",
        "outputId": "fec27f1b-21bb-485f-d4a6-a66f6ce214a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting ninja\n",
            "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (1.13)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "Installing collected packages: ninja, torch-geometric\n",
            "Successfully installed ninja-1.13.0 torch-geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get torch version\n",
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mbJBhN4lVgW",
        "outputId": "49c553b9-cf4f-471f-f4f5-46cefbd14a7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.8.0+cu126\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-cufile-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, setuptools, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install correct version of torch-scatter (depending on which torch version...)\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.8.0+cu126.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oHIAZKFlYzV",
        "outputId": "b70fe00f-91e9-49bc-aaa4-895d72a3fbd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt28cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run example for transductive dataset on GPU\n",
        "!python script/run.py -c config/transductive/inference.yaml --dataset CoDExSmall --epochs 0 --bpe null --gpus [0] --ckpt /content/ULTRA/ckpts/ultra_4g.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFDIWMFflmEP",
        "outputId": "0c7b790e-c494-49ed-98f1-1dbba59d67f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13:24:26   Random seed: 1024\n",
            "13:24:26   Config file: config/transductive/inference.yaml\n",
            "13:24:26   {'checkpoint': '/content/ULTRA/ckpts/ultra_4g.pth',\n",
            " 'dataset': {'class': 'CoDExSmall', 'root': '~/git/ULTRA/kg-datasets/'},\n",
            " 'model': {'class': 'Ultra',\n",
            "           'entity_model': {'aggregate_func': 'sum',\n",
            "                            'class': 'EntityNBFNet',\n",
            "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
            "                            'input_dim': 64,\n",
            "                            'layer_norm': True,\n",
            "                            'message_func': 'distmult',\n",
            "                            'short_cut': True},\n",
            "           'relation_model': {'aggregate_func': 'sum',\n",
            "                              'class': 'RelNBFNet',\n",
            "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
            "                              'input_dim': 64,\n",
            "                              'layer_norm': True,\n",
            "                              'message_func': 'distmult',\n",
            "                              'short_cut': True}},\n",
            " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
            " 'output_dir': '~/git/ULTRA/output',\n",
            " 'task': {'adversarial_temperature': 1,\n",
            "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
            "          'name': 'TransductiveInference',\n",
            "          'num_negative': 256,\n",
            "          'strict_negative': True},\n",
            " 'train': {'batch_per_epoch': None,\n",
            "           'batch_size': 8,\n",
            "           'gpus': [0],\n",
            "           'log_interval': 100,\n",
            "           'num_epoch': 0}}\n",
            "13:24:26   CoDExSmall dataset\n",
            "13:24:26   #train: 32888, #valid: 1827, #test: 1828\n",
            "13:24:27   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:24:27   Evaluate on valid\n",
            "Load rspmm extension. This may take a while...\n",
            "W0922 13:24:27.696000 5907 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W0922 13:24:27.696000 5907 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
            "13:25:46   mr: 38.5285\n",
            "13:25:46   mrr: 0.477777\n",
            "13:25:46   hits@1: 0.37329\n",
            "13:25:46   hits@3: 0.529557\n",
            "13:25:46   hits@10: 0.676793\n",
            "13:25:46   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:25:46   Evaluate on test\n",
            "13:25:53   mr: 42.3884\n",
            "13:25:53   mrr: 0.463778\n",
            "13:25:53   hits@1: 0.360503\n",
            "13:25:53   hits@3: 0.514497\n",
            "13:25:53   hits@10: 0.665208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run transductive inference with finetuning for 1 epoch\n",
        "!python script/run.py -c config/transductive/inference.yaml --dataset CoDExSmall --epochs 1 --bpe null --gpus [0] --ckpt /content/ULTRA/ckpts/ultra_4g.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30a-pygAqxPl",
        "outputId": "23e4e34a-f4ff-42d0-a3c5-9fa5a4b2b2ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13:45:57   Random seed: 1024\n",
            "13:45:57   Config file: config/transductive/inference.yaml\n",
            "13:45:57   {'checkpoint': '/content/ULTRA/ckpts/ultra_4g.pth',\n",
            " 'dataset': {'class': 'CoDExSmall', 'root': '~/git/ULTRA/kg-datasets/'},\n",
            " 'model': {'class': 'Ultra',\n",
            "           'entity_model': {'aggregate_func': 'sum',\n",
            "                            'class': 'EntityNBFNet',\n",
            "                            'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
            "                            'input_dim': 64,\n",
            "                            'layer_norm': True,\n",
            "                            'message_func': 'distmult',\n",
            "                            'short_cut': True},\n",
            "           'relation_model': {'aggregate_func': 'sum',\n",
            "                              'class': 'RelNBFNet',\n",
            "                              'hidden_dims': [64, 64, 64, 64, 64, 64],\n",
            "                              'input_dim': 64,\n",
            "                              'layer_norm': True,\n",
            "                              'message_func': 'distmult',\n",
            "                              'short_cut': True}},\n",
            " 'optimizer': {'class': 'AdamW', 'lr': 0.0005},\n",
            " 'output_dir': '~/git/ULTRA/output',\n",
            " 'task': {'adversarial_temperature': 1,\n",
            "          'metric': ['mr', 'mrr', 'hits@1', 'hits@3', 'hits@10'],\n",
            "          'name': 'TransductiveInference',\n",
            "          'num_negative': 256,\n",
            "          'strict_negative': True},\n",
            " 'train': {'batch_per_epoch': None,\n",
            "           'batch_size': 8,\n",
            "           'gpus': [0],\n",
            "           'log_interval': 100,\n",
            "           'num_epoch': 1}}\n",
            "13:45:57   CoDExSmall dataset\n",
            "13:45:57   #train: 32888, #valid: 1827, #test: 1828\n",
            "13:45:57   ------------------------------\n",
            "13:45:57   Number of parameters: 168705\n",
            "13:45:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:45:57   Epoch 0 begin\n",
            "Load rspmm extension. This may take a while...\n",
            "W0922 13:45:58.621000 11559 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "W0922 13:45:58.621000 11559 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.\n",
            "13:45:59   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "/content/ULTRA/script/run.py:85: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "  logger.warning(\"binary cross entropy: %g\" % loss)\n",
            "13:45:59   binary cross entropy: 0.581825\n",
            "13:46:02   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:02   binary cross entropy: 0.603752\n",
            "13:46:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:05   binary cross entropy: 0.583505\n",
            "13:46:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:08   binary cross entropy: 0.755574\n",
            "13:46:11   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:11   binary cross entropy: 0.482747\n",
            "13:46:14   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:14   binary cross entropy: 0.566077\n",
            "13:46:17   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:17   binary cross entropy: 0.5557\n",
            "13:46:20   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:20   binary cross entropy: 0.581736\n",
            "13:46:23   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:23   binary cross entropy: 0.457987\n",
            "13:46:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:26   binary cross entropy: 0.694554\n",
            "13:46:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:29   binary cross entropy: 0.739981\n",
            "13:46:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:32   binary cross entropy: 0.541289\n",
            "13:46:35   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:35   binary cross entropy: 0.381289\n",
            "13:46:38   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:38   binary cross entropy: 0.637086\n",
            "13:46:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:41   binary cross entropy: 0.488116\n",
            "13:46:45   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:45   binary cross entropy: 0.482826\n",
            "13:46:48   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:48   binary cross entropy: 0.494483\n",
            "13:46:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:51   binary cross entropy: 0.58585\n",
            "13:46:54   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:54   binary cross entropy: 0.53292\n",
            "13:46:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:46:57   binary cross entropy: 0.3779\n",
            "13:47:00   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:00   binary cross entropy: 0.459749\n",
            "13:47:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:04   binary cross entropy: 0.453147\n",
            "13:47:07   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:07   binary cross entropy: 0.559194\n",
            "13:47:10   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:10   binary cross entropy: 0.584186\n",
            "13:47:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:13   binary cross entropy: 0.392453\n",
            "13:47:16   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:16   binary cross entropy: 0.491312\n",
            "13:47:19   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:19   binary cross entropy: 0.486404\n",
            "13:47:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:22   binary cross entropy: 0.662451\n",
            "13:47:25   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:25   binary cross entropy: 0.614798\n",
            "13:47:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:28   binary cross entropy: 0.48627\n",
            "13:47:31   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:31   binary cross entropy: 0.673913\n",
            "13:47:35   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:35   binary cross entropy: 0.524311\n",
            "13:47:38   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:38   binary cross entropy: 0.654399\n",
            "13:47:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:41   binary cross entropy: 0.617587\n",
            "13:47:44   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:44   binary cross entropy: 0.364777\n",
            "13:47:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:47   binary cross entropy: 0.510963\n",
            "13:47:50   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:50   binary cross entropy: 0.559655\n",
            "13:47:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:53   binary cross entropy: 0.68998\n",
            "13:47:56   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:56   binary cross entropy: 0.610468\n",
            "13:47:59   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:47:59   binary cross entropy: 0.553804\n",
            "13:48:02   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:02   binary cross entropy: 0.523267\n",
            "13:48:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:05   binary cross entropy: 0.515505\n",
            "13:48:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:06   Epoch 0 end\n",
            "13:48:06   ------------------------------\n",
            "13:48:06   average binary cross entropy: 0.524533\n",
            "13:48:06   Save checkpoint to model_epoch_1.pth\n",
            "13:48:06   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:06   Evaluate on valid\n",
            "13:48:13   mr: 37.6541\n",
            "13:48:13   mrr: 0.49577\n",
            "13:48:13   hits@1: 0.392447\n",
            "13:48:13   hits@3: 0.550082\n",
            "13:48:13   hits@10: 0.692118\n",
            "13:48:13   Load checkpoint from model_epoch_1.pth\n",
            "13:48:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:13   Evaluate on valid\n",
            "13:48:20   mr: 37.6541\n",
            "13:48:20   mrr: 0.49577\n",
            "13:48:20   hits@1: 0.392447\n",
            "13:48:20   hits@3: 0.550082\n",
            "13:48:20   hits@10: 0.692118\n",
            "13:48:20   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "13:48:20   Evaluate on test\n",
            "13:48:27   mr: 39.9891\n",
            "13:48:27   mrr: 0.482909\n",
            "13:48:27   hits@1: 0.382659\n",
            "13:48:27   hits@3: 0.527899\n",
            "13:48:27   hits@10: 0.678337\n"
          ]
        }
      ]
    }
  ]
}